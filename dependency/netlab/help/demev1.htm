<html>
<head>
<title>
Netlab Reference Manual demev1
</title>
</head>
<body>
<H1> demev1
</H1>
<h2>
Purpose
</h2>
Demonstrate Bayesian regression for the MLP.

<p><h2>
Synopsis
</h2>
<PRE>
demev1</PRE>


<p><h2>
Description
</h2>
The problem consists an input variable <CODE>x</CODE> which sampled from a
Gaussian distribution, and a target variable <CODE>t</CODE> generated by
computing <CODE>sin(2*pi*x)</CODE> and adding Gaussian noise. A 2-layer
network with linear outputs is trained by minimizing a sum-of-squares
error function with isotropic Gaussian regularizer, using the scaled
conjugate gradient optimizer. The hyperparameters <CODE>alpha</CODE> and
<CODE>beta</CODE> are re-estimated using the function <CODE>evidence</CODE>. A graph 
is plotted of the original function, the training data, the trained
network function, and the error bars.

<p><h2>
See Also
</h2>
<CODE><a href="evidence.htm">evidence</a></CODE>, <CODE><a href="mlp.htm">mlp</a></CODE>, <CODE><a href="scg.htm">scg</a></CODE>, <CODE><a href="demard.htm">demard</a></CODE>, <CODE><a href="demmlp1.htm">demmlp1</a></CODE><hr>
<b>Pages:</b>
<a href="index.htm">Index</a>
<hr>
<p>Copyright (c) Ian T Nabney (1996-9)


</body>
</html>